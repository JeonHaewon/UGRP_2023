{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f19733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e8b393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def contrastive_loss(y_true, y_pred, margin=1):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "def contrastive_loss_with_margin(margin):\n",
    "    def contrastive_loss_inner(y_true, y_pred):\n",
    "        return contrastive_loss(y_true, y_pred, margin)\n",
    "    return contrastive_loss_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799e43be",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects = {\n",
    "    'euclidean_distance': euclidean_distance,\n",
    "    'contrastive_loss': contrastive_loss,\n",
    "    'contrastive_loss_with_margin': contrastive_loss_with_margin(margin=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f4619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_model = load_model('C:\\\\Users\\\\new_folder\\\\models\\\\MFCC_model.h5', custom_objects=custom_objects)\n",
    "cg_model = load_model('C:\\\\Users\\\\new_folder\\\\models\\\\cg_model.h5', custom_objects=custom_objects)\n",
    "sg_model = load_model('C:\\\\Users\\\\new_folder\\\\models\\\\sg_model.h5', custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f0e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_vector_a = np.random.normal(0, 1, (13, 2498))\n",
    "mfcc_vector_b = -mfcc_vector_a\n",
    "mfcc_vector_a = mfcc_vector_a.reshape(1, 13, -1)\n",
    "mfcc_vector_b = mfcc_vector_b.reshape(1, 13, -1)\n",
    "\n",
    "cg_vector_a = np.random.normal(0, 1, (12, 2498))\n",
    "cg_vector_b = -cg_vector_a\n",
    "cg_vector_a = cg_vector_a.reshape(1, 12, -1)\n",
    "cg_vector_b = cg_vector_b.reshape(1, 12, -1)\n",
    "\n",
    "sg_vector_a = np.random.normal(0, 1, (1025, 2498))\n",
    "sg_vector_b = -sg_vector_a\n",
    "sg_vector_a = sg_vector_a.reshape(1, 1025, -1)\n",
    "sg_vector_b = sg_vector_b.reshape(1, 1025, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bf98d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_min_score = mfcc_model.predict([mfcc_vector_a, mfcc_vector_b])\n",
    "mfcc_max_score = mfcc_model.predict([mfcc_vector_a, mfcc_vector_a])\n",
    "\n",
    "cg_min_score = cg_model.predict([cg_vector_a, cg_vector_b])\n",
    "cg_max_score = cg_model.predict([cg_vector_a, cg_vector_a])\n",
    "\n",
    "sg_min_score = sg_model.predict([sg_vector_a, sg_vector_b])\n",
    "sg_max_score = sg_model.predict([sg_vector_a, sg_vector_a])\n",
    "\n",
    "print(mfcc_min_score,mfcc_max_score,cg_min_score,cg_max_score,sg_min_score,sg_max_score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc06ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_normalize_value(x, min_val=mfcc_max_score, max_val=mfcc_min_score):\n",
    "    return (x - min_val) / (max_val - min_val)\n",
    "\n",
    "def cg_normalize_value(x, min_val=cg_max_score, max_val=cg_min_score):\n",
    "    return (x - min_val) / (max_val - min_val)\n",
    "\n",
    "def sg_normalize_value(x, min_val=sg_max_score, max_val=sg_min_score):\n",
    "    return (x - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bba520",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_vector1 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\1.1 표절_29s_mfcc.npy')\n",
    "mfcc_vector2 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\1.1 표절 key 3_29s_mfcc.npy')\n",
    "mfcc_vector3 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\1.1 표절 key -3_29s_mfcc.npy')\n",
    "mfcc_vector4 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\1.1 표절 noise 1_29s_mfcc.npy')\n",
    "mfcc_vector5 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\1.1 표절 noise 2_29s_mfcc.npy')\n",
    "mfcc_vector6 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\1.2 표절_29s_mfcc.npy')\n",
    "\n",
    "mfcc_vector7 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\2.1 표절_29s_mfcc.npy')\n",
    "mfcc_vector8 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\2.1 표절 key -3_29s_mfcc.npy')\n",
    "mfcc_vector9 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\2.1 표절_29s_mfcc.npy')\n",
    "mfcc_vector10 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\2.1 표절 key -3_29s_mfcc.npy')\n",
    "mfcc_vector11 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\2.1 표절_29s_mfcc.npy')\n",
    "mfcc_vector12 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\2.2 표절_29s_mfcc.npy')\n",
    "\n",
    "mfcc_vector13 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\3.1 커버_29s_mfcc.npy')\n",
    "mfcc_vector14 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\3.1 커버 key 3_29s_mfcc.npy')\n",
    "mfcc_vector15 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\3.1 커버 key -3_29s_mfcc.npy')\n",
    "mfcc_vector16 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\3.1 커버 noise 1_29s_mfcc.npy')\n",
    "mfcc_vector17 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\3.1 커버 noise 2_29s_mfcc.npy')\n",
    "mfcc_vector18 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\3.2 커버_29s_mfcc.npy')\n",
    "\n",
    "mfcc_vector19 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\4.1 커버_29s_mfcc.npy')\n",
    "mfcc_vector20 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\4.1 커버 key 3_29s_mfcc.npy')\n",
    "mfcc_vector21 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\4.1 커버 key -3_29s_mfcc.npy')\n",
    "mfcc_vector22 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\4.1 커버 noise 1_29s_mfcc.npy')\n",
    "mfcc_vector23 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\4.1 커버 noise 2_29s_mfcc.npy')\n",
    "mfcc_vector24 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\4.2 커버_29s_mfcc.npy')\n",
    "\n",
    "mfcc_vector25 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\5.1 샘플링_29s_mfcc.npy')\n",
    "mfcc_vector26 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\5.1 샘플링 key 3_29s_mfcc.npy')\n",
    "mfcc_vector27 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\5.1 샘플링 key -3_29s_mfcc.npy')\n",
    "mfcc_vector28 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\5.1 샘플링 noise 1_29s_mfcc.npy')\n",
    "mfcc_vector29 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\5.1 샘플링 noise 2_29s_mfcc.npy')\n",
    "mfcc_vector30 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\5.2 샘플링_29s_mfcc.npy')\n",
    "\n",
    "mfcc_vector31 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\6.1 샘플링_29s_mfcc.npy')\n",
    "mfcc_vector32 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\6.1 샘플링 key 3_29s_mfcc.npy')\n",
    "mfcc_vector33 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\6.1 샘플링 key -3_29s_mfcc.npy')\n",
    "mfcc_vector34 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\6.1 샘플링 noise 1_29s_mfcc.npy')\n",
    "mfcc_vector35 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\6.1 샘플링 noise 2_29s_mfcc.npy')\n",
    "mfcc_vector36 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\6.2 샘플링_29s_mfcc.npy')\n",
    "\n",
    "mfcc_vector37 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_mfcc\\\\7.1 다른곡_29s_mfcc.npy')\n",
    "\n",
    "\n",
    "for i in range(1, 38):\n",
    "    globals()[f'mfcc_vector{i}'] =  globals()[f'mfcc_vector{i}'].reshape(1, 13, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ccdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_vector1 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\1.1 표절_29s_cg.npy')\n",
    "cg_vector2 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\1.1 표절 key 3_29s_cg.npy')\n",
    "cg_vector3 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\1.1 표절 key -3_29s_cg.npy')\n",
    "cg_vector4 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\1.1 표절 noise 1_29s_cg.npy')\n",
    "cg_vector5 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\1.1 표절 noise 2_29s_cg.npy')\n",
    "cg_vector6 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\1.2 표절_29s_cg.npy')\n",
    "\n",
    "cg_vector7 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\2.1 표절_29s_cg.npy')\n",
    "cg_vector8 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\2.1 표절 key -3_29s_cg.npy')\n",
    "cg_vector9 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\2.1 표절_29s_cg.npy')\n",
    "cg_vector10 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\2.1 표절 key -3_29s_cg.npy')\n",
    "cg_vector11 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\2.1 표절_29s_cg.npy')\n",
    "cg_vector12 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\2.2 표절_29s_cg.npy')\n",
    "\n",
    "cg_vector13 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\3.1 커버_29s_cg.npy')\n",
    "cg_vector14 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\3.1 커버 key 3_29s_cg.npy')\n",
    "cg_vector15 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\3.1 커버 key -3_29s_cg.npy')\n",
    "cg_vector16 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\3.1 커버 noise 1_29s_cg.npy')\n",
    "cg_vector17 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\3.1 커버 noise 2_29s_cg.npy')\n",
    "cg_vector18 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\3.2 커버_29s_cg.npy')\n",
    "\n",
    "cg_vector19 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\4.1 커버_29s_cg.npy')\n",
    "cg_vector20 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\4.1 커버 key 3_29s_cg.npy')\n",
    "cg_vector21 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\4.1 커버 key -3_29s_cg.npy')\n",
    "cg_vector22 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\4.1 커버 noise 1_29s_cg.npy')\n",
    "cg_vector23 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\4.1 커버 noise 2_29s_cg.npy')\n",
    "cg_vector24 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\4.2 커버_29s_cg.npy')\n",
    "\n",
    "cg_vector25 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\5.1 샘플링_29s_cg.npy')\n",
    "cg_vector26 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\5.1 샘플링 key 3_29s_cg.npy')\n",
    "cg_vector27 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\5.1 샘플링 key -3_29s_cg.npy')\n",
    "cg_vector28 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\5.1 샘플링 noise 1_29s_cg.npy')\n",
    "cg_vector29 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\5.1 샘플링 noise 2_29s_cg.npy')\n",
    "cg_vector30 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\5.2 샘플링_29s_cg.npy')\n",
    "\n",
    "cg_vector31 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\6.1 샘플링_29s_cg.npy')\n",
    "cg_vector32 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\6.1 샘플링 key 3_29s_cg.npy')\n",
    "cg_vector33 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\6.1 샘플링 key -3_29s_cg.npy')\n",
    "cg_vector34 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\6.1 샘플링 noise 1_29s_cg.npy')\n",
    "cg_vector35 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\6.1 샘플링 noise 2_29s_cg.npy')\n",
    "cg_vector36 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\6.2 샘플링_29s_cg.npy')\n",
    "\n",
    "cg_vector37 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_cg\\\\7.1 다른곡_29s_cg.npy')\n",
    "\n",
    "\n",
    "for i in range(1, 38):\n",
    "    globals()[f'cg_vector{i}'] =  globals()[f'cg_vector{i}'].reshape(1, 12, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36a5fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_vector1 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\1.1 표절_29s_sg.npy')\n",
    "sg_vector2 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\1.1 표절 key 3_29s_sg.npy')\n",
    "sg_vector3 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\1.1 표절 key -3_29s_sg.npy')\n",
    "sg_vector4 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\1.1 표절 noise 1_29s_sg.npy')\n",
    "sg_vector5 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\1.1 표절 noise 2_29s_sg.npy')\n",
    "sg_vector6 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\1.2 표절_29s_sg.npy')\n",
    "\n",
    "sg_vector7 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\2.1 표절_29s_sg.npy')\n",
    "sg_vector8 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\2.1 표절 key -3_29s_sg.npy')\n",
    "sg_vector9 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\2.1 표절_29s_sg.npy')\n",
    "sg_vector10 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\2.1 표절 key -3_29s_sg.npy')\n",
    "sg_vector11 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\2.1 표절_29s_sg.npy')\n",
    "sg_vector12 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\2.2 표절_29s_sg.npy')\n",
    "\n",
    "sg_vector13 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\3.1 커버_29s_sg.npy')\n",
    "sg_vector14 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\3.1 커버 key 3_29s_sg.npy')\n",
    "sg_vector15 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\3.1 커버 key -3_29s_sg.npy')\n",
    "sg_vector16 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\3.1 커버 noise 1_29s_sg.npy')\n",
    "sg_vector17 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\3.1 커버 noise 2_29s_sg.npy')\n",
    "sg_vector18 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\3.2 커버_29s_sg.npy')\n",
    "\n",
    "sg_vector19 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\4.1 커버_29s_sg.npy')\n",
    "sg_vector20 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\4.1 커버 key 3_29s_sg.npy')\n",
    "sg_vector21 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\4.1 커버 key -3_29s_sg.npy')\n",
    "sg_vector22 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\4.1 커버 noise 1_29s_sg.npy')\n",
    "sg_vector23 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\4.1 커버 noise 2_29s_sg.npy')\n",
    "sg_vector24 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\4.2 커버_29s_sg.npy')\n",
    "\n",
    "sg_vector25 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\5.1 샘플링_29s_sg.npy')\n",
    "sg_vector26 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\5.1 샘플링 key 3_29s_sg.npy')\n",
    "sg_vector27 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\5.1 샘플링 key -3_29s_sg.npy')\n",
    "sg_vector28 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\5.1 샘플링 noise 1_29s_sg.npy')\n",
    "sg_vector29 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\5.1 샘플링 noise 2_29s_sg.npy')\n",
    "sg_vector30 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\5.2 샘플링_29s_sg.npy')\n",
    "\n",
    "sg_vector31 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\6.1 샘플링_29s_sg.npy')\n",
    "sg_vector32 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\6.1 샘플링 key 3_29s_sg.npy')\n",
    "sg_vector33 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\6.1 샘플링 key -3_29s_sg.npy')\n",
    "sg_vector34 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\6.1 샘플링 noise 1_29s_sg.npy')\n",
    "sg_vector35 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\6.1 샘플링 noise 2_29s_sg.npy')\n",
    "sg_vector36 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\6.2 샘플링_29s_sg.npy')\n",
    "\n",
    "sg_vector37 = np.load('C:\\\\Users\\\\haim1\\\\new_folder\\\\test_sg\\\\7.1 다른곡_29s_sg.npy')\n",
    "\n",
    "\n",
    "for i in range(1, 38):\n",
    "    globals()[f'sg_vector{i}'] =  globals()[f'sg_vector{i}'].reshape(1, 1025, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1830ad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Result of MFCC\\n\")\n",
    "\n",
    "print('[1.1 vs 1.1 key 3]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector1, mfcc_vector2]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector1, mfcc_vector2])), \"\\n\")\n",
    "\n",
    "print('[1.1 vs 1.1 key -3]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector1, mfcc_vector3]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector1, mfcc_vector3])), \"\\n\")\n",
    "\n",
    "print('[1.1 vs 1.1 noise 1]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector1, mfcc_vector4]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector1, mfcc_vector4])), \"\\n\")\n",
    "\n",
    "print('[1.1 vs 1.1 noise 2]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector1, mfcc_vector5]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector1, mfcc_vector5])), \"\\n\")\n",
    "\n",
    "print('[1.1 vs 다른 노래]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector1, mfcc_vector37]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector1, mfcc_vector37])), \"\\n\")\n",
    "\n",
    "print('[1.1 vs 1.2]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector1, mfcc_vector6]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector1, mfcc_vector6])), \"\\n\")\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "print('[2.1 vs 2.1 key 3]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector7, mfcc_vector8]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector7, mfcc_vector8])), \"\\n\")\n",
    "\n",
    "print('[2.1 vs 2.1 key -3]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector7, mfcc_vector9]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector7, mfcc_vector9])), \"\\n\")\n",
    "\n",
    "print('[2.1 vs 2.1 noise 1]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector7, mfcc_vector10]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector7, mfcc_vector10])), \"\\n\")\n",
    "\n",
    "print('[2.1 vs 2.1 noise 2]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector7, mfcc_vector11]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector7, mfcc_vector11])), \"\\n\")\n",
    "\n",
    "print('[2.1 vs 다른 노래]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector7, mfcc_vector37]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector7, mfcc_vector37])), \"\\n\")\n",
    "\n",
    "print('[2.1 vs 2.2]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector7, mfcc_vector12]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector7, mfcc_vector12])), \"\\n\")\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "print('[3.1 vs 3.1 key 3]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector13, mfcc_vector14]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector13, mfcc_vector14])), \"\\n\")\n",
    "\n",
    "print('[3.1 vs 3.1 key -3]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector13, mfcc_vector15]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector13, mfcc_vector15])), \"\\n\")\n",
    "\n",
    "print('[3.1 vs 3.1 noise 1]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector13, mfcc_vector16]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector13, mfcc_vector16])), \"\\n\")\n",
    "\n",
    "print('[3.1 vs 3.1 noise 2]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector13, mfcc_vector17]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector13, mfcc_vector17])), \"\\n\")\n",
    "\n",
    "print('[3.1 vs 다른 노래]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector13, mfcc_vector37]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector13, mfcc_vector37])), \"\\n\")\n",
    "\n",
    "print('[3.1 vs 3.2]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector13, mfcc_vector18]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector13, mfcc_vector18])), \"\\n\")\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "print('[4.1 vs 4.1 key 3]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector19, mfcc_vector20]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector19, mfcc_vector20])), \"\\n\")\n",
    "\n",
    "print('[4.1 vs 4.1 key -3]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector19, mfcc_vector21]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector19, mfcc_vector21])), \"\\n\")\n",
    "\n",
    "print('[4.1 vs 4.1 noise 1]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector19, mfcc_vector22]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector19, mfcc_vector22])), \"\\n\")\n",
    "\n",
    "print('[4.1 vs 4.1 noise 2]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector19, mfcc_vector23]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector19, mfcc_vector23])), \"\\n\")\n",
    "\n",
    "print('[4.1 vs 다른 노래]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector19, mfcc_vector37]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector19, mfcc_vector37])), \"\\n\")\n",
    "\n",
    "print('[4.1 vs 4.2]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector19, mfcc_vector24]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector19, mfcc_vector24])), \"\\n\")\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "print('[5.1 vs 5.1 key 3]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector25, mfcc_vector26]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector25, mfcc_vector26])), \"\\n\")\n",
    "\n",
    "print('[5.1 vs 5.1 key -3]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector25, mfcc_vector27]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector25, mfcc_vector27])), \"\\n\")\n",
    "\n",
    "print('[5.1 vs 5.1 noise 1]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector25, mfcc_vector28]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector25, mfcc_vector28])), \"\\n\")\n",
    "\n",
    "print('[5.1 vs 5.1 noise 2]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector25, mfcc_vector29]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector25, mfcc_vector29])), \"\\n\")\n",
    "\n",
    "print('[5.1 vs 다른 노래]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector25, mfcc_vector37]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector25, mfcc_vector37])), \"\\n\")\n",
    "\n",
    "print('[5.1 vs 5.2]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector25, mfcc_vector30]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector25, mfcc_vector30])), \"\\n\")\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "print('[6.1 vs 6.1 key 3]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector31, mfcc_vector32]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector31, mfcc_vector32])), \"\\n\")\n",
    "\n",
    "print('[6.1 vs 6.1 key -3]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector31, mfcc_vector33]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector31, mfcc_vector33])), \"\\n\")\n",
    "\n",
    "print('[6.1 vs 6.1 noise 1]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector31, mfcc_vector34]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector31, mfcc_vector34])), \"\\n\")\n",
    "\n",
    "print('[6.1 vs 6.1 noise 2]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector31, mfcc_vector35]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector31, mfcc_vector35])), \"\\n\")\n",
    "\n",
    "print('[6.1 vs 다른 노래]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector31, mfcc_vector37]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector31, mfcc_vector37])), \"\\n\")\n",
    "\n",
    "print('[6.1 vs 6.2]\\n유클리디안 거리:', mfcc_model.predict([mfcc_vector31, mfcc_vector36]))\n",
    "print('유사도:', mfcc_normalize_value(mfcc_model.predict([mfcc_vector31, mfcc_vector36])), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096f36f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Result of CG\\n\")\n",
    "\n",
    "print('[1.1 vs 1.1 key 3]\\n유클리디안 거리:', cg_model.predict([cg_vector1, cg_vector2]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector1, cg_vector2])), \"\\n\")\n",
    "\n",
    "print('[1.1 vs 1.1 key -3]\\n유클리디안 거리:', cg_model.predict([cg_vector1, cg_vector3]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector1, cg_vector3])), \"\\n\")\n",
    "\n",
    "print('[1.1 vs 1.1 noise 1]\\n유클리디안 거리:', cg_model.predict([cg_vector1, cg_vector4]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector1, cg_vector4])), \"\\n\")\n",
    "\n",
    "print('[1.1 vs 1.1 noise 2]\\n유클리디안 거리:', cg_model.predict([cg_vector1, cg_vector5]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector1, cg_vector5])), \"\\n\")\n",
    "\n",
    "print('[1.1 vs 다른 노래]\\n유클리디안 거리:', cg_model.predict([cg_vector1, cg_vector37]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector1, cg_vector37])), \"\\n\")\n",
    "\n",
    "print('[1.1 vs 1.2]\\n유클리디안 거리:', cg_model.predict([cg_vector1, cg_vector6]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector1, cg_vector6])), \"\\n\")\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "print('[2.1 vs 2.1 key 3]\\n유클리디안 거리:', cg_model.predict([cg_vector7, cg_vector8]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector7, cg_vector8])), \"\\n\")\n",
    "\n",
    "print('[2.1 vs 2.1 key -3]\\n유클리디안 거리:', cg_model.predict([cg_vector7, cg_vector9]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector7, cg_vector9])), \"\\n\")\n",
    "\n",
    "print('[2.1 vs 2.1 noise 1]\\n유클리디안 거리:', cg_model.predict([cg_vector7, cg_vector10]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector7, cg_vector10])), \"\\n\")\n",
    "\n",
    "print('[2.1 vs 2.1 noise 2]\\n유클리디안 거리:', cg_model.predict([cg_vector7, cg_vector11]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector7, cg_vector11])), \"\\n\")\n",
    "\n",
    "print('[2.1 vs 다른 노래]\\n유클리디안 거리:', cg_model.predict([cg_vector7, cg_vector37]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector7, cg_vector37])), \"\\n\")\n",
    "\n",
    "print('[2.1 vs 2.2]\\n유클리디안 거리:', cg_model.predict([cg_vector7, cg_vector12]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector7, cg_vector12])), \"\\n\")\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "print('[3.1 vs 3.1 key 3]\\n유클리디안 거리:', cg_model.predict([cg_vector13, cg_vector14]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector13, cg_vector14])), \"\\n\")\n",
    "\n",
    "print('[3.1 vs 3.1 key -3]\\n유클리디안 거리:', cg_model.predict([cg_vector13, cg_vector15]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector13, cg_vector15])), \"\\n\")\n",
    "\n",
    "print('[3.1 vs 3.1 noise 1]\\n유클리디안 거리:', cg_model.predict([cg_vector13, cg_vector16]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector13, cg_vector16])), \"\\n\")\n",
    "\n",
    "print('[3.1 vs 3.1 noise 2]\\n유클리디안 거리:', cg_model.predict([cg_vector13, cg_vector17]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector13, cg_vector17])), \"\\n\")\n",
    "\n",
    "print('[3.1 vs 다른 노래]\\n유클리디안 거리:', cg_model.predict([cg_vector13, cg_vector37]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector13, cg_vector37])), \"\\n\")\n",
    "\n",
    "print('[3.1 vs 3.2]\\n유클리디안 거리:', cg_model.predict([cg_vector13, cg_vector18]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector13, cg_vector18])), \"\\n\")\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "print('[4.1 vs 4.1 key 3]\\n유클리디안 거리:', cg_model.predict([cg_vector19, cg_vector20]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector19, cg_vector20])), \"\\n\")\n",
    "\n",
    "print('[4.1 vs 4.1 key -3]\\n유클리디안 거리:', cg_model.predict([cg_vector19, cg_vector21]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector19, cg_vector21])), \"\\n\")\n",
    "\n",
    "print('[4.1 vs 4.1 noise 1]\\n유클리디안 거리:', cg_model.predict([cg_vector19, cg_vector22]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector19, cg_vector22])), \"\\n\")\n",
    "\n",
    "print('[4.1 vs 4.1 noise 2]\\n유클리디안 거리:', cg_model.predict([cg_vector19, cg_vector23]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector19, cg_vector23])), \"\\n\")\n",
    "\n",
    "print('[4.1 vs 다른 노래]\\n유클리디안 거리:', cg_model.predict([cg_vector19, cg_vector37]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector19, cg_vector37])), \"\\n\")\n",
    "\n",
    "print('[4.1 vs 4.2]\\n유클리디안 거리:', cg_model.predict([cg_vector19, cg_vector24]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector19, cg_vector24])), \"\\n\")\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "print('[5.1 vs 5.1 key 3]\\n유클리디안 거리:', cg_model.predict([cg_vector25, cg_vector26]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector25, cg_vector26])), \"\\n\")\n",
    "\n",
    "print('[5.1 vs 5.1 key -3]\\n유클리디안 거리:', cg_model.predict([cg_vector25, cg_vector27]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector25, cg_vector27])), \"\\n\")\n",
    "\n",
    "print('[5.1 vs 5.1 noise 1]\\n유클리디안 거리:', cg_model.predict([cg_vector25, cg_vector28]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector25, cg_vector28])), \"\\n\")\n",
    "\n",
    "print('[5.1 vs 5.1 noise 2]\\n유클리디안 거리:', cg_model.predict([cg_vector25, cg_vector29]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector25, cg_vector29])), \"\\n\")\n",
    "\n",
    "print('[5.1 vs 다른 노래]\\n유클리디안 거리:', cg_model.predict([cg_vector25, cg_vector37]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector25, cg_vector37])), \"\\n\")\n",
    "\n",
    "print('[5.1 vs 5.2]\\n유클리디안 거리:', cg_model.predict([cg_vector25, cg_vector30]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector25, cg_vector30])), \"\\n\")\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "print('[6.1 vs 6.1 key 3]\\n유클리디안 거리:', cg_model.predict([cg_vector31, cg_vector32]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector31, cg_vector32])), \"\\n\")\n",
    "\n",
    "print('[6.1 vs 6.1 key -3]\\n유클리디안 거리:', cg_model.predict([cg_vector31, cg_vector33]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector31, cg_vector33])), \"\\n\")\n",
    "\n",
    "print('[6.1 vs 6.1 noise 1]\\n유클리디안 거리:', cg_model.predict([cg_vector31, cg_vector34]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector31, cg_vector34])), \"\\n\")\n",
    "\n",
    "print('[6.1 vs 6.1 noise 2]\\n유클리디안 거리:', cg_model.predict([cg_vector31, cg_vector35]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector31, cg_vector35])), \"\\n\")\n",
    "\n",
    "print('[6.1 vs 다른 노래]\\n유클리디안 거리:', cg_model.predict([cg_vector31, cg_vector37]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector31, cg_vector37])), \"\\n\")\n",
    "\n",
    "print('[6.1 vs 6.2]\\n유클리디안 거리:', cg_model.predict([cg_vector31, cg_vector36]))\n",
    "print('유사도:', cg_normalize_value(cg_model.predict([cg_vector31, cg_vector36])), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d4b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Result of SG\\n\")\n",
    "\n",
    "print('[1.1 vs 1.1 key 3]\\n유클리디안 거리:', sg_model.predict([sg_vector1, sg_vector2]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector1, sg_vector2])), \"\\n\")\n",
    "\n",
    "print('[1.1 vs 1.1 key -3]\\n유클리디안 거리:', sg_model.predict([sg_vector1, sg_vector3]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector1, sg_vector3])), \"\\n\")\n",
    "\n",
    "print('[1.1 vs 1.1 noise 1]\\n유클리디안 거리:', sg_model.predict([sg_vector1, sg_vector4]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector1, sg_vector4])), \"\\n\")\n",
    "\n",
    "print('[1.1 vs 1.1 noise 2]\\n유클리디안 거리:', sg_model.predict([sg_vector1, sg_vector5]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector1, sg_vector5])), \"\\n\")\n",
    "\n",
    "print('[1.1 vs 다른 노래]\\n유클리디안 거리:', sg_model.predict([sg_vector1, sg_vector37]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector1, sg_vector37])), \"\\n\")\n",
    "\n",
    "print('[1.1 vs 1.2]\\n유클리디안 거리:', sg_model.predict([sg_vector1, sg_vector6]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector1, sg_vector6])), \"\\n\")\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "print('[2.1 vs 2.1 key 3]\\n유클리디안 거리:', sg_model.predict([sg_vector7, sg_vector8]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector7, sg_vector8])), \"\\n\")\n",
    "\n",
    "print('[2.1 vs 2.1 key -3]\\n유클리디안 거리:', sg_model.predict([sg_vector7, sg_vector9]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector7, sg_vector9])), \"\\n\")\n",
    "\n",
    "print('[2.1 vs 2.1 noise 1]\\n유클리디안 거리:', sg_model.predict([sg_vector7, sg_vector10]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector7, sg_vector10])), \"\\n\")\n",
    "\n",
    "print('[2.1 vs 2.1 noise 2]\\n유클리디안 거리:', sg_model.predict([sg_vector7, sg_vector11]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector7, sg_vector11])), \"\\n\")\n",
    "\n",
    "print('[2.1 vs 다른 노래]\\n유클리디안 거리:', sg_model.predict([sg_vector7, sg_vector37]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector7, sg_vector37])), \"\\n\")\n",
    "\n",
    "print('[2.1 vs 2.2]\\n유클리디안 거리:', sg_model.predict([sg_vector7, sg_vector12]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector7, sg_vector12])), \"\\n\")\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "print('[3.1 vs 3.1 key 3]\\n유클리디안 거리:', sg_model.predict([sg_vector13, sg_vector14]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector13, sg_vector14])), \"\\n\")\n",
    "\n",
    "print('[3.1 vs 3.1 key -3]\\n유클리디안 거리:', sg_model.predict([sg_vector13, sg_vector15]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector13, sg_vector15])), \"\\n\")\n",
    "\n",
    "print('[3.1 vs 3.1 noise 1]\\n유클리디안 거리:', sg_model.predict([sg_vector13, sg_vector16]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector13, sg_vector16])), \"\\n\")\n",
    "\n",
    "print('[3.1 vs 3.1 noise 2]\\n유클리디안 거리:', sg_model.predict([sg_vector13, sg_vector17]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector13, sg_vector17])), \"\\n\")\n",
    "\n",
    "print('[3.1 vs 다른 노래]\\n유클리디안 거리:', sg_model.predict([sg_vector13, sg_vector37]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector13, sg_vector37])), \"\\n\")\n",
    "\n",
    "print('[3.1 vs 3.2]\\n유클리디안 거리:', sg_model.predict([sg_vector13, sg_vector18]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector13, sg_vector18])), \"\\n\")\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "print('[4.1 vs 4.1 key 3]\\n유클리디안 거리:', sg_model.predict([sg_vector19, sg_vector20]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector19, sg_vector20])), \"\\n\")\n",
    "\n",
    "print('[4.1 vs 4.1 key -3]\\n유클리디안 거리:', sg_model.predict([sg_vector19, sg_vector21]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector19, sg_vector21])), \"\\n\")\n",
    "\n",
    "print('[4.1 vs 4.1 noise 1]\\n유클리디안 거리:', sg_model.predict([sg_vector19, sg_vector22]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector19, sg_vector22])), \"\\n\")\n",
    "\n",
    "print('[4.1 vs 4.1 noise 2]\\n유클리디안 거리:', sg_model.predict([sg_vector19, sg_vector23]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector19, sg_vector23])), \"\\n\")\n",
    "\n",
    "print('[4.1 vs 다른 노래]\\n유클리디안 거리:', sg_model.predict([sg_vector19, sg_vector37]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector19, sg_vector37])), \"\\n\")\n",
    "\n",
    "print('[4.1 vs 4.2]\\n유클리디안 거리:', sg_model.predict([sg_vector19, sg_vector24]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector19, sg_vector24])), \"\\n\")\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "print('[5.1 vs 5.1 key 3]\\n유클리디안 거리:', sg_model.predict([sg_vector25, sg_vector26]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector25, sg_vector26])), \"\\n\")\n",
    "\n",
    "print('[5.1 vs 5.1 key -3]\\n유클리디안 거리:', sg_model.predict([sg_vector25, sg_vector27]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector25, sg_vector27])), \"\\n\")\n",
    "\n",
    "print('[5.1 vs 5.1 noise 1]\\n유클리디안 거리:', sg_model.predict([sg_vector25, sg_vector28]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector25, sg_vector28])), \"\\n\")\n",
    "\n",
    "print('[5.1 vs 5.1 noise 2]\\n유클리디안 거리:', sg_model.predict([sg_vector25, sg_vector29]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector25, sg_vector29])), \"\\n\")\n",
    "\n",
    "print('[5.1 vs 다른 노래]\\n유클리디안 거리:', sg_model.predict([sg_vector25, sg_vector37]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector25, sg_vector37])), \"\\n\")\n",
    "\n",
    "print('[5.1 vs 5.2]\\n유클리디안 거리:', sg_model.predict([sg_vector25, sg_vector30]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector25, sg_vector30])), \"\\n\")\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "print('[6.1 vs 6.1 key 3]\\n유클리디안 거리:', sg_model.predict([sg_vector31, sg_vector32]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector31, sg_vector32])), \"\\n\")\n",
    "\n",
    "print('[6.1 vs 6.1 key -3]\\n유클리디안 거리:', sg_model.predict([sg_vector31, sg_vector33]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector31, sg_vector33])), \"\\n\")\n",
    "\n",
    "print('[6.1 vs 6.1 noise 1]\\n유클리디안 거리:', sg_model.predict([sg_vector31, sg_vector34]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector31, sg_vector34])), \"\\n\")\n",
    "\n",
    "print('[6.1 vs 6.1 noise 2]\\n유클리디안 거리:', sg_model.predict([sg_vector31, sg_vector35]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector31, sg_vector35])), \"\\n\")\n",
    "\n",
    "print('[6.1 vs 다른 노래]\\n유클리디안 거리:', sg_model.predict([sg_vector31, sg_vector37]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector31, sg_vector37])), \"\\n\")\n",
    "\n",
    "print('[6.1 vs 6.2]\\n유클리디안 거리:', sg_model.predict([sg_vector31, sg_vector36]))\n",
    "print('유사도:', sg_normalize_value(sg_model.predict([sg_vector31, sg_vector36])), \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
